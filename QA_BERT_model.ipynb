{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QA BERT model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUPP8BWiivN5Pwg7jUfGcW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supertime1/BERT/blob/main/QA_BERT_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz4W_-pMVJsX"
      },
      "source": [
        "#1.Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orAMKxKkU_Vh"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import nltk \r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "from transformers import *"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCBMIvtlVRYq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlt53u2UVlb-"
      },
      "source": [
        "#2.Preprocess the input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvX_Xm1AVotx"
      },
      "source": [
        "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\r\n",
        "def prepare_bert_input(question, passage, tokenizer, max_seq_length=384):\r\n",
        "    \"\"\"\r\n",
        "    Prepare question and passage for input to BERT. \r\n",
        "\r\n",
        "    Args:\r\n",
        "        question (string): question string\r\n",
        "        passage (string): passage string where answer should lie\r\n",
        "        tokenizer (Tokenizer): used for transforming raw string input\r\n",
        "        max_seq_length (int): length of BERT input\r\n",
        "    \r\n",
        "    Returns:\r\n",
        "        input_ids (tf.Tensor): tensor of size (1, max_seq_length) which holds\r\n",
        "                               ids of tokens in input\r\n",
        "        input_mask (list): list of length max_seq_length of 1s and 0s with 1s\r\n",
        "                           in indices corresponding to input tokens, 0s in\r\n",
        "                           indices corresponding to padding\r\n",
        "        tokens (list): list of length of actual string tokens corresponding to input_ids\r\n",
        "    \"\"\"\r\n",
        "    # tokenize question\r\n",
        "    question_tokens = tokenizer.tokenize(question)\r\n",
        "    \r\n",
        "    # tokenize passage\r\n",
        "    passage_token = tokenizer.tokenize(passage)\r\n",
        "\r\n",
        "    # get special tokens \r\n",
        "    CLS = tokenizer.cls_token\r\n",
        "    SEP = tokenizer.sep_token\r\n",
        "    \r\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\r\n",
        "    \r\n",
        "    # manipulate tokens to get input in correct form (not adding padding yet)\r\n",
        "    # CLS {question_tokens} SEP {answer_tokens} \r\n",
        "    # This should be a list of tokens\r\n",
        "    tokens = [CLS] + question_tokens + [SEP] + passage_token\r\n",
        "\r\n",
        "    \r\n",
        "    # Convert tokens into integer IDs.\r\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\r\n",
        "    \r\n",
        "    # Create an input mask which has integer 1 for each token in the 'tokens' list\r\n",
        "    input_mask = [1]*len(tokens)\r\n",
        "\r\n",
        "    # pad input_ids with 0s until it is the max_seq_length\r\n",
        "    # Create padding for input_ids by creating a list of zeros [0,0,...0]\r\n",
        "    # Add the padding to input_ids so that its length equals max_seq_length\r\n",
        "    input_ids = input_ids + [0]*(max_seq_length - len(tokens))\r\n",
        "    \r\n",
        "    # Do the same to pad the input_mask so its length is max_seq_length\r\n",
        "    input_mask = input_mask + [0]*(max_seq_length - len(input_mask))\r\n",
        "\r\n",
        "    # END CODE HERE\r\n",
        "\r\n",
        "    return tf.expand_dims(tf.convert_to_tensor(input_ids), 0), input_mask, tokens  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm2VRL-ZX3dG"
      },
      "source": [
        "passage = \"My name is Bob.\"\r\n",
        "\r\n",
        "question = \"What is my name?\"\r\n",
        "\r\n",
        "input_ids, input_mask, tokens = prepare_bert_input(question, passage, tokenizer, 20)\r\n",
        "print(\"Test Case:\\n\")\r\n",
        "print(\"Passage: {}\".format(passage))\r\n",
        "print(\"Question: {}\".format(question))\r\n",
        "print()\r\n",
        "print(\"Tokens:\")\r\n",
        "print(tokens)\r\n",
        "print(\"\\nCorresponding input IDs:\")\r\n",
        "print(input_ids)\r\n",
        "print(\"\\nMask:\")\r\n",
        "print(input_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovpD8XkfVpTU"
      },
      "source": [
        "#3.Download a BERT model and fine-tune it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m61IJ0VrVvPw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2cYcF0_Vvxv"
      },
      "source": [
        "#4.Evaluate the QA model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoywxGkzVxO3"
      },
      "source": [
        "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\r\n",
        "def get_span_from_scores(start_scores, end_scores, input_mask, verbose=False):\r\n",
        "    \"\"\"\r\n",
        "    Find start and end indices that maximize sum of start score\r\n",
        "    and end score, subject to the constraint that start is before end\r\n",
        "    and both are valid according to input_mask.\r\n",
        "\r\n",
        "    Args:\r\n",
        "        start_scores (list): contains scores for start positions, shape (1, n)\r\n",
        "        end_scores (list): constains scores for end positions, shape (1, n)\r\n",
        "        input_mask (list): 1 for valid positions and 0 otherwise\r\n",
        "    \"\"\"\r\n",
        "    n = len(start_scores)\r\n",
        "    max_start_i = -1\r\n",
        "    max_end_j = -1\r\n",
        "    max_start_score = -np.inf\r\n",
        "    max_end_score = -np.inf\r\n",
        "    max_sum = -np.inf\r\n",
        "    \r\n",
        "    # Find i and j that maximizes start_scores[i] + end_scores[j]\r\n",
        "    # so that i <= j and input_mask[i] == input_mask[j] == 1\r\n",
        "    \r\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\r\n",
        "    # set the range for i\r\n",
        "    for i in range(n): # complete this line\r\n",
        "        \r\n",
        "        # set the range for j\r\n",
        "        for j in range(i,n): #complete this line\r\n",
        "\r\n",
        "            # both input masks should be 1\r\n",
        "            if input_mask[i] == input_mask[j] == 1: # complete this line\r\n",
        "                \r\n",
        "                # check if the sum of the start and end scores is greater than the previous max sum\r\n",
        "                if start_scores[i] + end_scores[j] > max_sum: # complete this line\r\n",
        "\r\n",
        "                    # calculate the new max sum\r\n",
        "                    max_sum = start_scores[i] + end_scores[j]\r\n",
        "        \r\n",
        "                    # save the index of the max start score\r\n",
        "                    max_start_i = i\r\n",
        "                \r\n",
        "                    # save the index for the max end score\r\n",
        "                    max_end_j = j\r\n",
        "                    \r\n",
        "                    # save the value of the max start score\r\n",
        "                    max_start_val = start_scores[i]\r\n",
        "                    \r\n",
        "                    # save the value of the max end score\r\n",
        "                    max_end_val = end_scores[j]\r\n",
        "                                        \r\n",
        "    ### END CODE HERE ###\r\n",
        "    if verbose:\r\n",
        "        print(f\"max start is at index i={max_start_i} and score {max_start_val}\")\r\n",
        "        print(f\"max end is at index i={max_end_j} and score {max_end_val}\")\r\n",
        "        print(f\"max start + max end sum of scores is {max_sum}\")\r\n",
        "    return max_start_i, max_end_j"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MWkZ00dX_9g"
      },
      "source": [
        "start_scores = tf.convert_to_tensor([-1, 2, 0.4, -0.3, 0, 8, 10, 12], dtype=float)\r\n",
        "end_scores = tf.convert_to_tensor([5, 1, 1, 3, 4, 10, 10, 10], dtype=float)\r\n",
        "input_mask = [1, 1, 1, 1, 1, 0, 0, 0]\r\n",
        "\r\n",
        "start, end = get_span_from_scores(start_scores, end_scores, input_mask, verbose=True)\r\n",
        "\r\n",
        "print(\"Expected: (1, 4) \\nReturned: ({}, {})\".format(start, end))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffj6ze7HYA8n"
      },
      "source": [
        "# Test 2\r\n",
        "\r\n",
        "start_scores = tf.convert_to_tensor([0, 2, -1, 0.4, -0.3, 0, 8, 10, 12], dtype=float)\r\n",
        "end_scores = tf.convert_to_tensor([0, 5, 1, 1, 3, 4, 10, 10, 10], dtype=float)\r\n",
        "input_mask = [1, 1, 1, 1, 1, 0, 0, 0, 0 ]\r\n",
        "\r\n",
        "start, end = get_span_from_scores(start_scores, end_scores, input_mask, verbose=True)\r\n",
        "\r\n",
        "print(\"Expected: (1, 1) \\nReturned: ({}, {})\".format(start, end))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAY_eV2iYCiz"
      },
      "source": [
        "# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\r\n",
        "def construct_answer(tokens):\r\n",
        "    \"\"\"\r\n",
        "    Combine tokens into a string, remove some hash symbols, and leading/trailing whitespace.\r\n",
        "    Args:\r\n",
        "        tokens: a list of tokens (strings)\r\n",
        "    \r\n",
        "    Returns:\r\n",
        "        out_string: the processed string.\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\r\n",
        "    \r\n",
        "    # join the tokens together with whitespace\r\n",
        "    out_string = \" \".join(tokens)\r\n",
        "    \r\n",
        "    # replace ' ##' with empty string\r\n",
        "    out_string = out_string.replace(' ##','')\r\n",
        "    \r\n",
        "    # remove leading and trailing whitespace\r\n",
        "    out_string = out_string.strip()\r\n",
        "\r\n",
        "    ### END CODE HERE ###\r\n",
        "    \r\n",
        "    # if there is an '@' symbol in the tokens, remove all whitespace\r\n",
        "    if '@' in tokens:\r\n",
        "        out_string = out_string.replace(' ', '')\r\n",
        "\r\n",
        "    return out_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QHvFNh7YEKW"
      },
      "source": [
        "# Test\r\n",
        "\r\n",
        "tmp_tokens_1 = [' ## hello', 'how ', 'are ', 'you?      ']\r\n",
        "tmp_out_string_1 = construct_answer(tmp_tokens_1)\r\n",
        "\r\n",
        "print(f\"tmp_out_string_1: {tmp_out_string_1}, length {len(tmp_out_string_1)}\")\r\n",
        "\r\n",
        "\r\n",
        "tmp_tokens_2 = ['@',' ## hello', 'how ', 'are ', 'you?      ']\r\n",
        "tmp_out_string_2 = construct_answer(tmp_tokens_2)\r\n",
        "print(f\"tmp_out_string_2: {tmp_out_string_2}, length {len(tmp_out_string_2)}\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqsEHqCuYGpd"
      },
      "source": [
        "def get_model_answer(model, question, passage, tokenizer, max_seq_length=384):\r\n",
        "    \"\"\"\r\n",
        "    Identify answer in passage for a given question using BERT. \r\n",
        "\r\n",
        "    Args:\r\n",
        "        model (Model): pretrained Bert model which we'll use to answer questions\r\n",
        "        question (string): question string\r\n",
        "        passage (string): passage string\r\n",
        "        tokenizer (Tokenizer): used for preprocessing of input\r\n",
        "        max_seq_length (int): length of input for model\r\n",
        "        \r\n",
        "    Returns:\r\n",
        "        answer (string): answer to input question according to model\r\n",
        "    \"\"\" \r\n",
        "    # prepare input: use the function prepare_bert_input\r\n",
        "    input_ids, input_mask, tokens = prepare_bert_input(question, passage, tokenizer, max_seq_length)\r\n",
        "    \r\n",
        "    # get scores for start of answer and end of answer\r\n",
        "    # use the model returned by TFAutoModelForQuestionAnswering.from_pretrained(\"./models\")\r\n",
        "    # pass in in the input ids that are returned by prepare_bert_input\r\n",
        "    start_scores, end_scores = model(input_ids)\r\n",
        "    \r\n",
        "    # start_scores and end_scores will be tensors of shape [1,max_seq_length]\r\n",
        "    # To pass these into get_span_from_scores function, \r\n",
        "    # take the value at index 0 to get a tensor of shape [max_seq_length]\r\n",
        "    start_scores = start_scores[0]\r\n",
        "    end_scores = end_scores[0]\r\n",
        "    \r\n",
        "    # using scores, get most likely answer\r\n",
        "    # use the get_span_from_scores function\r\n",
        "    span_start, span_end = get_span_from_scores(start_scores, end_scores, input_mask)\r\n",
        "    \r\n",
        "    # Using array indexing to get the tokens from the span start to span end (including the span_end)\r\n",
        "    answer_tokens = tokens[span_start:span_end+1]\r\n",
        "    \r\n",
        "    # Combine the tokens into a single string and perform post-processing\r\n",
        "    # use construct_answer\r\n",
        "    answer = construct_answer(answer_tokens)\r\n",
        "    \r\n",
        "    return answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZavI0NGYISI"
      },
      "source": [
        "passage = \"Computational complexity theory is a branch of the theory \\\r\n",
        "           of computation in theoretical computer science that focuses \\\r\n",
        "           on classifying computational problems according to their inherent \\\r\n",
        "           difficulty, and relating those classes to each other. A computational \\\r\n",
        "           problem is understood to be a task that is in principle amenable to \\\r\n",
        "           being solved by a computer, which is equivalent to stating that the \\\r\n",
        "           problem may be solved by mechanical application of mathematical steps, \\\r\n",
        "           such as an algorithm.\"\r\n",
        "\r\n",
        "question = \"What branch of theoretical computer science deals with broadly \\\r\n",
        "            classifying computational problems by difficulty and class of relationship?\"\r\n",
        "\r\n",
        "print(\"Output: {}\".format(get_model_answer(model, question, passage, tokenizer)))\r\n",
        "print(\"Expected: Computational complexity theory\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGvk9SiYYJaE"
      },
      "source": [
        "passage = \"The word pharmacy is derived from its root word pharma which was a term used since \\\r\n",
        "           the 15th–17th centuries. However, the original Greek roots from pharmakos imply sorcery \\\r\n",
        "           or even poison. In addition to pharma responsibilities, the pharma offered general medical \\\r\n",
        "           advice and a range of services that are now performed solely by other specialist practitioners, \\\r\n",
        "           such as surgery and midwifery. The pharma (as it was referred to) often operated through a \\\r\n",
        "           retail shop which, in addition to ingredients for medicines, sold tobacco and patent medicines. \\\r\n",
        "           Often the place that did this was called an apothecary and several languages have this as the \\\r\n",
        "           dominant term, though their practices are more akin to a modern pharmacy, in English the term \\\r\n",
        "           apothecary would today be seen as outdated or only approproriate if herbal remedies were on offer \\\r\n",
        "           to a large extent. The pharmas also used many other herbs not listed. The Greek word Pharmakeia \\\r\n",
        "           (Greek: φαρμακεία) derives from pharmakon (φάρμακον), meaning 'drug', 'medicine' (or 'poison').\"\r\n",
        "\r\n",
        "question = \"What word is the word pharmacy taken from?\"\r\n",
        "\r\n",
        "print(\"Output: {}\".format(get_model_answer(model, question, passage, tokenizer)))\r\n",
        "print(\"Expected: pharma\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-l6i30iYKy4"
      },
      "source": [
        "passage = \"Abnormal echocardiogram findings and followup. Shortness of breath, congestive heart failure, \\\r\n",
        "           and valvular insufficiency. The patient complains of shortness of breath, which is worsening. \\\r\n",
        "           The patient underwent an echocardiogram, which shows severe mitral regurgitation and also large \\\r\n",
        "           pleural effusion. The patient is an 86-year-old female admitted for evaluation of abdominal pain \\\r\n",
        "           and bloody stools. The patient has colitis and also diverticulitis, undergoing treatment. \\\r\n",
        "           During the hospitalization, the patient complains of shortness of breath, which is worsening. \\\r\n",
        "           The patient underwent an echocardiogram, which shows severe mitral regurgitation and also large \\\r\n",
        "           pleural effusion. This consultation is for further evaluation in this regard. As per the patient, \\\r\n",
        "           she is an 86-year-old female, has limited activity level. She has been having shortness of breath \\\r\n",
        "           for many years. She also was told that she has a heart murmur, which was not followed through \\\r\n",
        "           on a regular basis.\"\r\n",
        "\r\n",
        "q1 = \"How old is the patient?\"\r\n",
        "q2 = \"Does the patient have any complaints?\"\r\n",
        "q3 = \"What is the reason for this consultation?\"\r\n",
        "q4 = \"What does her echocardiogram show?\"\r\n",
        "q5 = \"What other symptoms does the patient have?\"\r\n",
        "q6 = \"What is the gender of this patient?\"\r\n",
        "\r\n",
        "questions = [q6]\r\n",
        "\r\n",
        "for i, q in enumerate(questions):\r\n",
        "    print(\"Question {}: {}\".format(i+1, q))\r\n",
        "    print()\r\n",
        "    print(\"Answer: {}\".format(get_model_answer(model, q, passage, tokenizer)))\r\n",
        "    print()\r\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkHR8UBXVxyv"
      },
      "source": [
        "#5.Deploy the model on Django"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZO4HHHKV1UO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}